{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XgbJFu4PLPkI"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import os\n",
        "project_dir = '/content/drive/My Drive/cnn-dailymail-summarizer'\n",
        "os.chdir(project_dir)\n",
        "\n",
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jZklMGKwJR7D"
      },
      "outputs": [],
      "source": [
        "\n",
        "import pandas as pd\n",
        "from cnn_dailymail_news_text_summarizer.dataset import load_datasets\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import nltk\n",
        "from collections import Counter\n",
        "from collections import defaultdict\n",
        "import re\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from transformers import BartForConditionalGeneration, BartTokenizer, DataCollatorForSeq2Seq, AutoModelForSeq2SeqLM, Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
        "from datasets import Dataset\n",
        "import torch\n",
        "import evaluate"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available():\n",
        "    device_name = torch.device(\"cuda\")\n",
        "else:\n",
        "    device_name = torch.device('cpu')\n",
        "print(\"Using {}.\".format(device_name))"
      ],
      "metadata": {
        "id": "AQU2N8CxjSg2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7PMZ8Cc0JR7E"
      },
      "source": [
        "## Loading Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q0TZSQPYJR7G"
      },
      "outputs": [],
      "source": [
        "train_path = os.path.join(project_dir, 'data/raw/cnn_dailymail/train.csv')\n",
        "test_path = os.path.join(project_dir, 'data/raw/cnn_dailymail/test.csv')\n",
        "val_path = os.path.join(project_dir, 'data/raw/cnn_dailymail/validation.csv')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7BQG0kL4JR7G"
      },
      "outputs": [],
      "source": [
        "train_data, test_data, val_data = load_datasets(train_path, test_path, val_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E7pfifNlJR7H"
      },
      "outputs": [],
      "source": [
        "train_data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LrU2AQ_UJR7H"
      },
      "source": [
        "## Exploratory Data Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-cXr21O65QhU"
      },
      "outputs": [],
      "source": [
        "sample = train_data.sample()\n",
        "\n",
        "list(sample['article'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v_1d7alg594U"
      },
      "outputs": [],
      "source": [
        "list(sample['highlights'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FnUR2P34JR7H"
      },
      "outputs": [],
      "source": [
        "len(train_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IY9WelIl8dD_"
      },
      "source": [
        "### Counts and Lengths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jblbU7W4V7Bt"
      },
      "outputs": [],
      "source": [
        "eda_data = train_data.sample(frac=0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "laT4_EJ1JR7H"
      },
      "outputs": [],
      "source": [
        "plt.hist(eda_data['article'].str.len(), bins=50, edgecolor='white')\n",
        "plt.xlabel(\"Number of Characters in Article\")\n",
        "plt.ylabel(\"Number of Articles\")\n",
        "plt.title(\"Distribution of Characters per Article\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NgvePdElJR7I"
      },
      "outputs": [],
      "source": [
        "plt.hist(eda_data['article'].str.split().map(lambda x: len(x)), bins=50, edgecolor='white')\n",
        "plt.xlabel(\"Number of Words in Article\")\n",
        "plt.ylabel(\"Number of Articles\")\n",
        "plt.title(\"Distribution of Words per Article\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iLIBBNl14BP9"
      },
      "outputs": [],
      "source": [
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hcxuMs0N2adS"
      },
      "outputs": [],
      "source": [
        "plt.hist(eda_data['article'].apply(lambda x: len(nltk.sent_tokenize(x))), bins=50, edgecolor='white')\n",
        "plt.xlabel(\"Number of Sentences in Article\")\n",
        "plt.ylabel(\"Number of Articles\")\n",
        "plt.title(\"Distribution of Sentences per Article\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CD5omOAuJR7J"
      },
      "outputs": [],
      "source": [
        "eda_data['mean_word_length'] = eda_data['article'].map(lambda x : np.mean([len(word) for word in x.split()]))\n",
        "eda_data.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dtKvQLuDJR7J"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "sns.boxplot(data=eda_data, y='mean_word_length')\n",
        "plt.ylabel(\"Mean Word Length\")\n",
        "plt.title(\"Boxplot of Mean Word Length per Article\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rd80Px470pK0"
      },
      "outputs": [],
      "source": [
        "plt.hist(eda_data['highlights'].str.len(), bins=50, edgecolor='white')\n",
        "plt.xlabel(\"Number of Characters in Article Summary\")\n",
        "plt.ylabel(\"Number of Articles\")\n",
        "plt.title(\"Distribution of Characters per Article Summary\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A81bdVMx1I2s"
      },
      "outputs": [],
      "source": [
        "plt.hist(eda_data['highlights'].str.split().map(lambda x: len(x)), bins=50, edgecolor='white')\n",
        "plt.xlabel(\"Number of Words in Article Summary\")\n",
        "plt.ylabel(\"Number of Articles\")\n",
        "plt.title(\"Distribution of Words per Article Summary\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "won0nMQZ7EGC"
      },
      "outputs": [],
      "source": [
        "plt.hist(eda_data['highlights'].apply(lambda x: len(nltk.sent_tokenize(x))), bins=20, edgecolor='white')\n",
        "plt.xlabel(\"Number of Sentences in Article Summary\")\n",
        "plt.ylabel(\"Number of Articles\")\n",
        "plt.title(\"Distribution of Sentences per Article Summary\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iwXTy1cw8-db"
      },
      "source": [
        "### Term frequency"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "go0xV1Fo9Cbh"
      },
      "outputs": [],
      "source": [
        "eda_data.drop('mean_word_length', axis=1, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "40jrHzox-ACf"
      },
      "outputs": [],
      "source": [
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oJ9JvFMBLnWZ"
      },
      "outputs": [],
      "source": [
        "stop = set(nltk.corpus.stopwords.words('english'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t33m8tRPX-Km"
      },
      "outputs": [],
      "source": [
        "def remove_punctuation(text):\n",
        "    return re.sub(r'[^\\w\\s]', '', text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vk4gEETNMBV4"
      },
      "outputs": [],
      "source": [
        "corpus = []\n",
        "words = eda_data['article'].str.lower().apply(remove_punctuation).str.split()\n",
        "words = words.values.tolist()\n",
        "corpus = [word for i in words for word in i]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vood1kBtO0uA"
      },
      "outputs": [],
      "source": [
        "dic = defaultdict(int)\n",
        "for word in corpus:\n",
        "    if word in stop:\n",
        "        dic[word]+=1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YPAVO_t4PKpY"
      },
      "outputs": [],
      "source": [
        "top=sorted(dic.items(), key=lambda x:x[1],reverse=True)\n",
        "x,y=zip(*top)\n",
        "plt.figure(figsize=(14, 7))\n",
        "plt.bar(x[:40], y[:40], color='blue')\n",
        "plt.xlabel('Words')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Top 40 Most Frequent Stopwords')\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0V9F_Oi3P874"
      },
      "outputs": [],
      "source": [
        "counter=Counter(corpus)\n",
        "most=counter.most_common()\n",
        "\n",
        "x, y= [], []\n",
        "for word,count in most:\n",
        "    if (word not in stop):\n",
        "        x.append(word)\n",
        "        y.append(count)\n",
        "plt.figure(figsize=(14, 7))\n",
        "plt.bar(x[:40], y[:40], color='blue')\n",
        "plt.xlabel('Words')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Top 40 Most Frequent Non-Stopwords')\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vP6RjPiOYMTV"
      },
      "outputs": [],
      "source": [
        "eda_data = eda_data.sample(frac=0.1)\n",
        "eda_data['article'] = eda_data['article'].str.lower().apply(remove_punctuation)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8WjGmeRaYm_z"
      },
      "source": [
        "### N-gram frequency"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PX0ED2ULkhRm"
      },
      "outputs": [],
      "source": [
        "def get_top_ngram(corpus, stop_words, n=2):\n",
        "  cv = CountVectorizer(ngram_range=(n, n), stop_words=stop_words)\n",
        "  ngrams = cv.fit_transform(corpus)\n",
        "  count_values = ngrams.toarray().sum(axis=0)\n",
        "  ngram_freq = pd.DataFrame(sorted([(count_values[i], k) for k, i in cv.vocabulary_.items()], reverse = True))\n",
        "  ngram_freq.columns = ['frequency', 'ngram']\n",
        "  sns.barplot(x=ngram_freq['frequency'][:20], y=ngram_freq['ngram'][:20])\n",
        "  if n == 2:\n",
        "    plt.title('Top 20 Most Frequent Bigrams')\n",
        "  elif n == 3:\n",
        "    plt.title('Top 20 Most Frequent Trigrams')\n",
        "  else:\n",
        "    plt.title('Top 20 Most Frequent Ngrams')\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v4k4NZTymTq0"
      },
      "outputs": [],
      "source": [
        "get_top_ngram(eda_data['article'], list(stop), 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cBFZr7-1odn5"
      },
      "outputs": [],
      "source": [
        "get_top_ngram(eda_data['article'], list(stop), 3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "peyTO51caRZi"
      },
      "source": [
        "## Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-LOYJlY9aVRa"
      },
      "outputs": [],
      "source": [
        "checkpoint = \"facebook/bart-base\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nt-W6XMuajHx"
      },
      "outputs": [],
      "source": [
        "tokenizer = BartTokenizer.from_pretrained(checkpoint)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QyEJaYcwa58d"
      },
      "outputs": [],
      "source": [
        "tokenizer(train_data['article'][0])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pni0CHO6fl65"
      },
      "outputs": [],
      "source": [
        "prefix = \"summarize: \"\n",
        "def tokenization(examples):\n",
        "    inputs = [prefix + doc for doc in examples['article']]\n",
        "    model_inputs = tokenizer(inputs, max_length=512, truncation=True)\n",
        "\n",
        "    labels = tokenizer(text_target=examples[\"highlights\"], max_length=128, truncation=True)\n",
        "\n",
        "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
        "    return model_inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oLPtDxNXIOcA"
      },
      "outputs": [],
      "source": [
        "train_data_decr = train_data.sample(frac=0.05)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z5CpuYNdIwNV"
      },
      "outputs": [],
      "source": [
        "train_data_decr = Dataset.from_pandas(train_data_decr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q7YCBgq_JBPk"
      },
      "outputs": [],
      "source": [
        "train_data_decr = train_data_decr.map(tokenization, batched=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6TDgIwdENIF9"
      },
      "outputs": [],
      "source": [
        "print(train_data_decr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zt927OLO2zo7"
      },
      "outputs": [],
      "source": [
        "val_data_decr = val_data.sample(frac=0.05)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jBeS2Vg423ZE"
      },
      "outputs": [],
      "source": [
        "val_data_decr = Dataset.from_pandas(val_data_decr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AV1miML228Nm"
      },
      "outputs": [],
      "source": [
        "val_data_decr = val_data_decr.map(tokenization, batched=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pNi5edG8iqtC"
      },
      "outputs": [],
      "source": [
        "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=checkpoint, padding=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ytT5HidHi_op"
      },
      "outputs": [],
      "source": [
        "rouge = evaluate.load(\"rouge\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dAMZ0GNjjbPt"
      },
      "outputs": [],
      "source": [
        "def compute_metrics(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
        "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
        "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "\n",
        "    result = rouge.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)\n",
        "\n",
        "    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in predictions]\n",
        "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
        "\n",
        "    return {k: round(v, 4) for k, v in result.items()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BM1fjDXqy8DW"
      },
      "outputs": [],
      "source": [
        "model = AutoModelForSeq2SeqLM.from_pretrained(checkpoint)\n",
        "model.gradient_checkpointing_enable()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mkKylZ360h0-"
      },
      "outputs": [],
      "source": [
        "training_args = Seq2SeqTrainingArguments(\n",
        "    output_dir='./model',\n",
        "    num_train_epochs=3,\n",
        "    per_device_train_batch_size=32,\n",
        "    per_device_eval_batch_size=64,\n",
        "    gradient_accumulation_steps=4,\n",
        "    warmup_steps=100,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir='./logs',\n",
        "    logging_steps=10,\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    save_total_limit=2,\n",
        "    save_strategy=\"epoch\",\n",
        "    load_best_model_at_end=True,\n",
        "    predict_with_generate=True,\n",
        "    fp16=True,\n",
        "    remove_unused_columns=True\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KfmfmzwS2Nxk"
      },
      "outputs": [],
      "source": [
        "trainer = Seq2SeqTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_data_decr,\n",
        "    eval_dataset=val_data_decr,\n",
        "    data_collator=data_collator,\n",
        "    tokenizer=tokenizer\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-epUfE8O3Ovz"
      },
      "outputs": [],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BvHzJYa-dlbo"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.7"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}